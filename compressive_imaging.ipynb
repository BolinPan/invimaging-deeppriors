{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compressive Imaging with Deep Untrained Decoder Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num GPUs 0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from include import *\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import pywt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim\n",
    "from torch.autograd import Variable\n",
    "from sklearn import linear_model\n",
    "\n",
    "GPU = True\n",
    "if GPU == True:\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "    print(\"num GPUs\",torch.cuda.device_count())\n",
    "    device = 'cuda'\n",
    "    if torch.cuda.device_count()==0:\n",
    "        dtype = torch.FloatTensor\n",
    "        device = 'cpu'\n",
    "else:\n",
    "    dtype = torch.FloatTensor\n",
    "    device = 'cpu'\n",
    "from scipy.fftpack import dct\n",
    "from scipy.fftpack import idct\n",
    "from scipy import io as sio \n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load image and pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of input image: (1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "#dataset = 'mnist' # 'mnist' or 'celeba'\n",
    "dataset = 'mnist'\n",
    "path = './test_data/' + dataset + '/' \n",
    "img_name = dataset + '1' # 1-5 (for celeba), 1-6 (for mnist)\n",
    "img_path = path + img_name + \".jpg\"\n",
    "img_pil = Image.open(img_path)\n",
    "if dataset == 'celeba':\n",
    "    img_pil = img_pil.crop((60,80+20,60+64,80+84)) #crop to 3 x 64 x 64\n",
    "img_np = pil_to_np(img_pil)\n",
    "print('Dimensions of input image:', img_np.shape)\n",
    "img_np = img_np / np.max(img_np)\n",
    "img_np_orig = 1*img_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display image x and convert to pytorch variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if dataset == 'celeba':\n",
    "    plt.imshow(img_np.transpose(1,2,0))\n",
    "else:\n",
    "    plt.imshow(img_np[0,:,:])\n",
    "    plt.gray()\n",
    "plt.axis('off')\n",
    "img_var = np_to_var(img_np).type(dtype)\n",
    "d = img_np.shape[1]\n",
    "out_ch = img_np.shape[0]\n",
    "d_image = img_np.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select and set up model to run - denoise, CS, PR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed phase retrieval mode\n",
      "Compression rate is  0.3\n",
      "Number of measurements is  235  for signal of length  784\n"
     ]
    }
   ],
   "source": [
    "#choose mode, 1 (denoising) , 2 (compressed sensing), 3 (phase retrieval)\n",
    "mode = 3\n",
    "if mode==1:\n",
    "    f = 1 #(default)\n",
    "    print('Compression/denoising mode')\n",
    "    Ameas_var = 1\n",
    "    img_var_meas = img_var\n",
    "elif mode==2:\n",
    "    print('Compressed sensing mode')\n",
    "    f = 0.2 #compression rate\n",
    "    print('Compression rate is ', f)\n",
    "    m_image = int(f*d_image)\n",
    "    print('Number of measurements is ',m_image, ' for signal of length ', d_image)\n",
    "    # random Gaussian measurement matrix : A\n",
    "    Ameas = np.random.randn(m_image,d_image).astype(float)/np.sqrt(m_image)\n",
    "    Ameas_var = torch.from_numpy(Ameas).float().to(device)\n",
    "    # measurements : y = A*x\n",
    "    img_var_meas = torch.matmul(Ameas_var,img_var.to(device).reshape(d_image,1))\n",
    "if mode==3:\n",
    "    print('Compressed phase retrieval mode')    \n",
    "    f = 0.3 #compression rate\n",
    "    print('Compression rate is ', f)\n",
    "    m_image = int(f*d_image)\n",
    "    print('Number of measurements is ',m_image, ' for signal of length ', d_image)\n",
    "    # random Gaussian measurement matrix : A    \n",
    "    Ameas = np.random.randn(m_image,d_image).astype(float)/np.sqrt(m_image)\n",
    "    Ameas_var = torch.from_numpy(Ameas).float().to(device)\n",
    "    # full measurements : A*x\n",
    "    img_var_meas = torch.matmul(Ameas_var,img_var.to(device).reshape(d_image,1))      \n",
    "    # absolute valued measurements : y = |A*x|\n",
    "    img_var_meas = torch.abs(img_var_meas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use decoder architecture or DC GAN architecture\n",
    "decodetype = 'upsample' # transposeconv / upsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_scales= 3 num_channels_up= [25, 15, 10]\n",
      "number of parameters:  1800\n",
      "Sequential(\n",
      "  (dconv0): Sequential(\n",
      "    (0): ReflectionPad2d((0, 0, 0, 0))\n",
      "    (1): Conv2d(25, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (drelu0): ReLU()\n",
      "  (dbn0): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dups0): Upsample(scale_factor=2, mode=bilinear)\n",
      "  (dconv1): Sequential(\n",
      "    (0): ReflectionPad2d((0, 0, 0, 0))\n",
      "    (1): Conv2d(15, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (drelu1): ReLU()\n",
      "  (dbn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dups1): Upsample(scale_factor=2, mode=bilinear)\n",
      "  (dconv2): Sequential(\n",
      "    (0): ReflectionPad2d((0, 0, 0, 0))\n",
      "    (1): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (sig): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "if dataset == 'mnist':\n",
    "    num_channels = [25,15,10] \n",
    "elif dataset== 'celeba':    \n",
    "    num_channels = [120,25,15,10] \n",
    "output_depth = img_np.shape[0] # number of output channels\n",
    "net = autoencodernet(num_output_channels=output_depth,num_channels_up=num_channels,need_sigmoid=True, Ameas=Ameas_var,\n",
    "                        decodetype=decodetype\n",
    "                        ).type(dtype)\n",
    "\n",
    "print(\"number of parameters: \", num_param(net))\n",
    "if decodetype == 'upsample':\n",
    "    print(net.decoder)\n",
    "elif decodetype == 'transposeconv':\n",
    "    print(net.convdecoder)\n",
    "net_in = copy.deepcopy(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invert Image from Measurements with Deep Network Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of latent code B1:  [1, 25, 7, 7]\n",
      "initializing latent code B1...\n",
      "not optimizing over latent code Z1\n",
      "optimize decoder with SGD 0.08\n",
      "optimizing with gradient descent...\n",
      "\n",
      "LR is set to 0.08\n",
      "\n",
      "\n",
      "Iteration 02999   Train loss 0.002973                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
      "LR is set to 0.055999999999999994\n",
      "\n",
      "\n",
      "Iteration 03245   Train loss 0.002584                                                                                                                                                                                                                                                       "
     ]
    }
   ],
   "source": [
    "#pick optimization procedure\n",
    "optim = 'gd'             #'pgd' (projected gradient descent), 'gd' (gradient descent)\n",
    "if optim == 'pgd':\n",
    "    optimizer2='SGD'      #outer loop optimizer - 'SGD' (or try 'adam')\n",
    "    numit = 1000          #number of outer iterations of LS\n",
    "    LR_LS = 20            #typically 5-10 ; required for outer loop of LS\n",
    "\n",
    "    OPTIMIZER='SGD'       #inner loop optimizer - SGD or adam\n",
    "    numit_inner = 10      #number of inner loop iterations for projection\n",
    "    LR = 0.02             #typically 0.02-0.05 for pgd/inner loop of projection, higher for more complex structures\n",
    "\n",
    "    lr_decay_epoch = 500  #decay learning rates of both inner and outer optimizers\n",
    "    \n",
    "elif optim == 'gd':\n",
    "    OPTIMIZER='SGD'       #optimizer - SGD or adam \n",
    "    numit = 5000         #number of iterations for SGD\n",
    "    LR = 0.08              #typically 0.02-0.5 for gd , higher for more complex structures\n",
    "\n",
    "    optimizer2 = None                                    \n",
    "    numit_inner = None\n",
    "    LR_LS = None\n",
    "\n",
    "    lr_decay_epoch = 3000\n",
    "    \n",
    "t0 = time.time()\n",
    "mse_t, ni, net, ni_mod, in_np_img = fit( \n",
    "                            net=net,\n",
    "                            num_channels=num_channels,\n",
    "                            num_iter=numit,\n",
    "                            numit_inner = numit_inner,\n",
    "                            LR=LR,\n",
    "                            LR_LS = LR_LS,\n",
    "                            OPTIMIZER = OPTIMIZER,                          \n",
    "                            optimizer2 = optimizer2,             \n",
    "                            lr_decay_epoch = lr_decay_epoch,             \n",
    "                            img_clean_var=img_var_meas,\n",
    "                            find_best=True,\n",
    "                            Ameas = Ameas_var,\n",
    "                            model = mode,\n",
    "                            code='uniform',\n",
    "                            decodetype=decodetype,\n",
    "                            optim=optim,\n",
    "                            out_channels=out_ch        \n",
    "                            )\n",
    "t1 = time.time()\n",
    "print('\\ntime elapsed:',t1-t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('optimizer iteration')\n",
    "plt.ylabel('loss')\n",
    "plt.loglog(mse_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute initialization error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lvls = len(num_channels)\n",
    "if decodetype == 'upsample':\n",
    "    nettype = net.decoder\n",
    "    netintype = net_in.decoder\n",
    "elif decodetype == 'transposeconv':\n",
    "    nettype = net.convdecoder\n",
    "    netintype = net_in.convdecoder\n",
    "ComputeInitErr(nettype,netintype,lvls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display reconstructed image and statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_img_np = net( ni.type(dtype) ).data.cpu().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxv = np.max(img_np) \n",
    "print(\"Image inversion with Deep-Decoder, SNR: \" + str(psnr(img_np_orig,out_img_np,maxv)))  \n",
    "reconstruction_err = mse(img_np_orig,out_img_np,maxv)\n",
    "print('MSE:',reconstruction_err)\n",
    "if dataset == 'celeba':\n",
    "    plt.imshow(out_img_np.transpose(1,2,0))\n",
    "else:\n",
    "    plt.imshow(out_img_np[0,:,:])\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "save_path= optim+'_'+img_name+str(int(10*f))+'.png'\n",
    "savefig=False\n",
    "if savefig:\n",
    "    plt.savefig(save_path,bbox_inches='tight') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display initialization and statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_img = in_np_img.data.cpu().numpy()\n",
    "maxv = np.max(img_np) \n",
    "print(\"Image at random initialization of Deep-Decoder, SNR: \" + str(psnr(img_np_orig,in_img,maxv)))  \n",
    "reconstruction_err = mse(img_np_orig,in_img,maxv)\n",
    "print('MSE:',reconstruction_err)\n",
    "if dataset == 'celeba':\n",
    "    plt.imshow(in_img[0,:,:,:].transpose(1,2,0))\n",
    "else:\n",
    "    plt.imshow(in_img[0,0,:,:])\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "init_err = np.linalg.norm(out_img_np-in_img)/np.linalg.norm(out_img_np)\n",
    "print('Initialization error:', init_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image inversion with sparsity priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick sparsifying basis - Compute wavelet or cosine transforms operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis = 'DCT'              # spatial, DWT, DCT\n",
    "if basis == 'DWT': #wavelet transform\n",
    "    Winv = construct_Wminv(d=img_np.shape[1],wave_name='db1') #imported from wavelet_DCT_basis.py\n",
    "    d_wav_image = int(np.sqrt(Winv.shape[1]))\n",
    "    print('Size of image:', img_np.size, ', size of wavelet transform matrix:', Winv.shape)\n",
    "elif basis == 'DCT': #DCT transform    \n",
    "    Dinv = construct_IDCT2mat(d=d)                            #imported from wavelet_DCT_basis.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify measurement operator to incorporate transform "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsize = img_np.shape[1]*img_np.shape[2]\n",
    "A = Ameas\n",
    "if basis=='DWT': #wavelet\n",
    "    dwsize = Winv.shape[1]\n",
    "    Aeff = np.zeros((Ameas.shape[0],dwsize*out_ch))\n",
    "    for i in range(img_np.shape[0]):   \n",
    "        Anew = np.dot(A[:,i*dsize:(i+1)*dsize],Winv)\n",
    "        Aeff[:,i*dwsize:(i+1)*dwsize] = Anew\n",
    "elif basis=='DCT': #DCT\n",
    "    Aeff = np.zeros((Ameas.shape[0],dsize*out_ch))\n",
    "    for i in range(img_np.shape[0]):   \n",
    "        Aeff[:,i*dsize:(i+1)*dsize] = np.dot(A[:,i*dsize:(i+1)*dsize],Dinv)    \n",
    "else:    \n",
    "    Aeff = A\n",
    "y = img_var_meas.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store measurements and operator for MATLAB codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#used for comparisons - TVAL3, SPARTA (supplementary code note provided in current version, will be updated)\n",
    "save_mat = True\n",
    "if save_mat:\n",
    "    sio.savemat('A.mat', {'A':Aeff})\n",
    "    sio.savemat('y.mat', {'y':y})\n",
    "    sio.savemat('xtrue.mat',{'x_':np.ravel(img_np)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_vec = sio.loadmat('xtrue.mat')['x_']\n",
    "#img_vec = -img_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_vec.shape\n",
    "if mode==3:\n",
    "        if basis=='DWT': #wavelet\n",
    "            img_vec = np.reshape(img_vec,[img_np.shape[0],dwsize])\n",
    "            img_rec = np.zeros(img_np.shape)\n",
    "            for i in range(img_np.shape[0]):    \n",
    "                img_vec2 = np.dot(Winv,img_vec[i,:].T)\n",
    "                img_rec[i,:,:] = np.reshape(img_vec2,[img_np.shape[1],img_np.shape[2]])    \n",
    "        elif basis=='DCT': #DCT\n",
    "            img_vec = np.reshape(img_vec,[img_np.shape[0],dsize])\n",
    "            img_rec = np.zeros(img_np.shape)\n",
    "            for i in range(img_np.shape[0]):    \n",
    "                img_vec2 = np.dot(Dinv,img_vec[i,:].T)\n",
    "                img_rec[i,:,:] = np.reshape(img_vec2,[img_np.shape[1],img_np.shape[2]])                \n",
    "        else:\n",
    "            img_rec = np.reshape(img_vec,img_np.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compressed sensing and denoising with Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode==1 or mode==2:\n",
    "    t0 = time.time()\n",
    "    reg = linear_model.Lasso(alpha=1e-6) #(max_iter=10000, fit_intercept=False, tol=0.00001)\n",
    "    reg.fit(Aeff, y)  \n",
    "    img_vec = reg.coef_\n",
    "    if mode==2:\n",
    "        if basis=='DWT':\n",
    "            img_vec = np.reshape(img_vec,[img_np.shape[0],dwsize])\n",
    "            img_rec = np.zeros(img_np.shape)\n",
    "            for i in range(img_np.shape[0]):    \n",
    "                img_vec2 = np.dot(Winv,img_vec[i,:].T)\n",
    "                img_rec[i,:,:] = np.reshape(img_vec2,[img_np.shape[1],img_np.shape[2]])    \n",
    "        elif basis=='DCT':\n",
    "            img_vec = np.reshape(img_vec,[img_np.shape[0],dsize])\n",
    "            img_rec = np.zeros(img_np.shape)\n",
    "            for i in range(img_np.shape[0]):    \n",
    "                img_vec2 = np.dot(Dinv,img_vec[i,:].T)\n",
    "                img_rec[i,:,:] = np.reshape(img_vec2,[img_np.shape[1],img_np.shape[2]])                \n",
    "        else:\n",
    "            img_rec = np.reshape(img_vec,img_np.shape)\n",
    "    t1 = time.time()\n",
    "    print('Time taken for Lasso:',t1-t0)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display reconstructed image and statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode==1 or mode==2:\n",
    "    maxi = np.max(img_rec) \n",
    "    print(\"Image inversion with Lasso, SNR: \" + str(psnr(img_np_orig,img_rec,maxi))) \n",
    "    reconstruction_err = mse(img_np_orig,img_rec,maxi)\n",
    "    print('MSE:',reconstruction_err)\n",
    "    if out_ch==3:\n",
    "        plt.imshow(img_rec.transpose(1,2,0))\n",
    "    else: \n",
    "        plt.imshow(np.clip(img_rec[0,:,:],0,1))\n",
    "        plt.gray()\n",
    "    plt.axis('off') \n",
    "    plt.show()  \n",
    "    save_path= 'lasso_'+img_name+str(int(10*f))+'.png'\n",
    "    savefig=False\n",
    "    if savefig:\n",
    "        plt.savefig(save_path,bbox_inches='tight') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
